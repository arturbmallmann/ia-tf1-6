{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarefa 4 - MPL 4x3x2\n",
    "\n",
    "A seguir, você implementará uma rede 4x3x2 orientada a frente, com funções de ativação sigmóide em ambas as\n",
    "camadas.\n",
    "\n",
    "Coisas a fazer:\n",
    "\n",
    "● Calcular o input da camada oculta.\n",
    "\n",
    "● Calcular o output da camada oculta.\n",
    "\n",
    "● Calcular o input da camada de output.\n",
    "\n",
    "● Calcular o output da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sigmoid = lambda x: 1/(1 + np.exp(-x))\n",
    "\n",
    "inputs_ = [0.1,0.3,0.5,0.2]\n",
    "# tamanho: n_inputs é implícito\n",
    "# 4x3x2\n",
    "size = [len(inputs_),3,2] #camada interna e de saída eu decido\n",
    "sigmoid_prime = lambda x: x * (1 - x) #poupando recursos entra somente o output pois já calculou-se o sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero conseguir fazer uma rede neural totalmente flexível em relação ao seu tamanho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.20267242,  0.26536929, -0.53374646],\n",
       "        [-0.0102385 , -0.29370697,  0.19579899],\n",
       "        [ 0.84405596, -0.74217129,  0.2260542 ],\n",
       "        [-0.136907  ,  0.41303001, -0.3154333 ]]),\n",
       " array([[-0.89035619, -0.37402138],\n",
       "        [ 0.21975677,  0.19297469],\n",
       "        [-0.83349665, -0.37524789]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [np.random.normal(scale=inp**-.5, size=(inp,h)) for inp,h in zip(size,size[1:]) ]\n",
    "originais = weights\n",
    "bias = 0\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.])]\n",
      "[[0.1, 0.3, 0.5, 0.2], 0, 0]\n",
      "\n",
      "\n",
      "iteração nº: 0 camada:0\n",
      "input: [0.1, 0.3, 0.5, 0.2]\n",
      "output: [0.59177495 0.41336913 0.51382285]\n",
      "gradiente: [0.24157736 0.24249509 0.24980893]\n",
      "\n",
      "\n",
      "iteração nº: 0 camada:1\n",
      "input: [0.59177495 0.41336913 0.51382285]\n",
      "output: [0.29643768 0.41717586]\n",
      "gradiente: [0.20856238 0.24314016]\n"
     ]
    }
   ],
   "source": [
    "y = 0.2 #valor esperado\n",
    "learnrate = 0.5\n",
    "#loop\n",
    "weights = originais #pra não dar reset todas as vezes e poder comparar rodadas com mesmos pesos de início\n",
    "#it = 0\n",
    "erro_m = 1\n",
    "dw = [np.zeros(len(inputs_)) for x in range(3)]\n",
    "print(dw)\n",
    "inputs = [inputs_] + [0] * (len(size)-1)\n",
    "print(inputs)\n",
    "#for it in range(0,100): #100 ciclos a princípio\n",
    "for it in range(0,1): #apenas 1 ciclo para a questão numero 4\n",
    "    for camada in range(0,len(size) - 1):\n",
    "        print('\\n')\n",
    "        print(\"iteração nº: {} camada:{}\".format(it,camada))\n",
    "        h = np.dot(inputs[camada], weights[camada]) #multiplica peso e entrada e faz o somatório\n",
    "        output = sigmoid(h)\n",
    "        inputs[camada+1] = output\n",
    "        print (\"input: {}\\noutput: {}\".format(inputs[camada],output))\n",
    "      #  erro = y - output\n",
    "      #  print(\"erro: {}\".format(erro))\n",
    "        output_grad=sigmoid_prime(output)\n",
    "        print(\"gradiente: {}\".format(output_grad))\n",
    "\n",
    "     #   error_term = erro * output_grad\n",
    "     #   print (\"error term: {}\".format(error_term))\n",
    "      #  dw[camada] += [x*error_term for x in inputs[camada]] #Atualiza o passo! lista do np para isso funcionar\n",
    "      #  weights +=  [learnrate * w / it for w in dw] #atulizar pesos\n",
    "      #  print (\"passo: {}, pesos: {}\\n\".format(dw,weights))\n",
    "      #  erro_m = erro**2/it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
