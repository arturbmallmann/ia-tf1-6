{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarefa 4 - MPL 4x3x2\n",
    "\n",
    "A seguir, você implementará uma rede 4x3x2 orientada a frente, com funções de ativação sigmóide em ambas as\n",
    "camadas.\n",
    "\n",
    "Coisas a fazer:\n",
    "\n",
    "● Calcular o input da camada oculta.\n",
    "\n",
    "● Calcular o output da camada oculta.\n",
    "\n",
    "● Calcular o input da camada de output.\n",
    "\n",
    "● Calcular o output da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sigmoid = lambda x: 1/(1 + np.exp(-x))\n",
    "\n",
    "inputs_ = np.array([0.1,0.3,0.5,0.2])\n",
    "# tamanho: n_inputs é implícito\n",
    "# 4x3x2\n",
    "size = [len(inputs_),3,2] #camada interna e de saída eu decido\n",
    "sigmoid_prime = lambda x: x * (1 - x) #poupando recursos entra somente o output pois já calculou-se o sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suvenier rsrsrs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0%----------------------------------------------------]\n",
      "[=====10%----------------------------------------------]\n",
      "[==========20%-----------------------------------------]\n",
      "[===============30%------------------------------------]\n",
      "[====================40%-------------------------------]\n",
      "[=========================50%--------------------------]\n",
      "[==============================60%---------------------]\n",
      "[===================================70%----------------]\n",
      "[========================================80%-----------]\n",
      "[=============================================90%------]\n",
      "[==================================================100%]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class barrinha:\n",
    "    def __init__(self,total):\n",
    "        self.total = total -1\n",
    "        self.value = 0\n",
    "        self.foo = str(\"[\"+\"=\"*50+\"]\")\n",
    "        self.bar = str(\"[\"+\"-\"*50+\"]\")\n",
    "    def __str__(self):\n",
    "        pc = self.value/self.total\n",
    "        pcst = str(int(pc*100))\n",
    "        return self.foo[:1+int(pc*50)] +pcst+\"%---\"[:-len(pcst)]+ self.bar[1+int(pc*50):]\n",
    "    def refresh(self, value):\n",
    "        self.value = value\n",
    "\n",
    "        \n",
    "t = 11\n",
    "b = barrinha(t)\n",
    "for i in range(t):\n",
    "    b.refresh(i)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero conseguir fazer uma rede neural totalmente flexível em relação ao seu tamanho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.75464087,  0.15430334, -0.19026378],\n",
       "        [ 0.28046301, -0.48358496, -0.33929498],\n",
       "        [ 1.22951575, -0.27241465, -0.41206343],\n",
       "        [-0.38671205,  0.62785987, -0.07840794]]),\n",
       " array([[-0.34875502,  0.91027901],\n",
       "        [-0.34881469,  0.17398849],\n",
       "        [-1.02565156,  0.3043031 ]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [np.random.normal(scale=inp**-.5, size=(inp,h)) for inp,h in zip(size,size[1:]) ]\n",
    "originais = weights\n",
    "bias = 0\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw: [matrix([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]), matrix([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])]\n",
      "wires: [array([0.1, 0.3, 0.5, 0.2]), 0, 0]\n"
     ]
    }
   ],
   "source": [
    "y = [0.2, 0.3] #valor esperado\n",
    "learnrate = 0.5\n",
    "#loop\n",
    "weights = originais #pra não dar reset todas as vezes e poder comparar rodadas com mesmos pesos de início\n",
    "#it = 0\n",
    "dw = [np.matrix(np.zeros((x,y))) for x,y in zip(size,size[1:])]\n",
    "print(\"dw: {}\".format(dw))\n",
    "wires = [inputs_] + [0] * (len(size)-1)\n",
    "error_term = [0] * (len(size)-1)\n",
    "print(\"wires: {}\".format(wires))\n",
    "grads = [0] * (len(size)-1)\n",
    "\n",
    "#for it in range(0,100): #100 ciclos a princípio\n",
    "def foward(): #apenas 1 ciclo para a questão numero 4\n",
    "    for camada in range(0,len(size) - 1):\n",
    "        h = np.dot(wires[camada], weights[camada]) #multiplica peso e entrada e faz o somatório\n",
    "        output = sigmoid(h)\n",
    "        #error_term[camada+1] = np.zeros((len(output), size[camada+1]))\n",
    "        wires[camada+1] = output\n",
    "        print (\"=\"*camada+\">camada:{}\\ninput: {}\\noutput: {}\".format(camada,wires[camada],output))\n",
    "\n",
    "        grads[camada]=sigmoid_prime(output)\n",
    "        print(\"gradiente: {}\".format(grads[camada]))\n",
    "    yield foward()\n",
    "     #   error_term = erro * output_grad\n",
    "     #   print (\"error term: {}\".format(error_term))\n",
    "      #  dw[camada] += [x*error_term for x in inputs[camada]] #Atualiza o passo! lista do np para isso funcionar\n",
    "      #  weights +=  [learnrate * w / it for w in dw] #atulizar pesos\n",
    "      #  print (\"passo: {}, pesos: {}\\n\".format(dw,weights))\n",
    "      #  erro_m = erro**2/it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BackTracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(epoch):\n",
    "    print(\"\\nBack Propagation:\")\n",
    "    camada = -1 #última da lista de camadas\n",
    "    erro = y - wires[camada]\n",
    "    print(\"inputs outputs: {}\\n\".format(wires))\n",
    "    print(\"grads {}:\".format(grads[camada-1] ) )\n",
    "    print(\"weigths {}:\".format(weights[camada] ) )   \n",
    "    print(\"error_term {}:\".format(error_term ) )\n",
    "    print(\"grads * weights {}:\".format( (error_term[camada]* weights[camada]).T * grads[camada-1] ) )\n",
    "    error_term[camada] = erro * grads[camada] # err camada de saída * f'\n",
    "    error_term[camada-1] = (error_term[camada]* weights[camada]).T * grads[camada-1] # err camada oculta\n",
    "   # print(\"error_term: {}\".format(error_term))\n",
    "   # print(\"err_cam: {}\\nw_cam-1: {}\\ngrads_cam-1: {}\\n\".format( error_term[camada], weights[camada], grads[camada-1]))\n",
    "\n",
    "    print(\"=\"*(len(size)-1+camada)+\">camada {}\\ninput : {}\\noutput: {}\".format(camada + len(size)-1, wires[camada-1],wires[camada]))\n",
    "\n",
    "    print(\"erro: {}\".format(erro))\n",
    "    print(\"error_term: {}\".format(error_term))\n",
    "    print(\"pesos: {}\".format(weights[camada]))\n",
    "    \n",
    "    print(\"lole \\n{}\\ndw shape:{}\".format([error_term[camada] * x for x in wires[camada-1]],dw[camada]))\n",
    "    dw[camada] += np.matrix([error_term[camada] * x for x in wires[camada-1]]) #Atualiza o passo! lista do np para isso funcionar\n",
    "#    weights[camada] +=  [learnrate * w / epoch for w in dw[camada]] #atulizar pesos\n",
    "#    weights[camada] +=  [learnrate * w / epoch for w in dw[camada]] #atulizar pesos\n",
    "    atpeso = np.dot (learnrate / epoch+1,dw[camada])\n",
    "    weights [camada] += atpeso\n",
    "    print(\"pesos dw camada {}: \\n{}\".format(camada, dw[camada]))\n",
    "    print(\"pesos camada {}: \\n{}\".format(camada, weights[camada]))\n",
    "    print(\"inputs camada {}: \\n{}\".format(camada, wires[camada-1]))\n",
    "    for camada in range(camada - 1, -len(size), -1): # à partir da penúltima, visto que a última já sofreu a correção\n",
    "        print(\"=\"*(len(size)-1+camada)+\">camada {}\\ninput : {}\\noutput: {}\".format(camada + len(size)-1, wires[camada-1],wires[camada]))\n",
    "        if (len(size)-1+camada) != 0:\n",
    "            print((error_term[camada], weights[camada]))\n",
    "            error_term[camada-1] = (error_term[camada]* weights[camada]).T * grads[camada-1]\n",
    "       # dw[camada] += error_term[camada]\n",
    "        print(\"dwcamada:\\n{}\".format(dw[camada]))\n",
    "        print(\"wires caralho:\\n{}\".format(wires[camada-1]))\n",
    "        print(\"error_term:\\n{}\".format(error_term))\n",
    "        dw[camada] += [error_term[camada] * x for x in wires[camada-1]]\n",
    "        print(\"dwcamada:\\n{}\".format(dw[camada]))\n",
    "   #     weights[camada] += np.dot (learnrate / epoch+1,dw[camada])\n",
    "        pass\n",
    "    yield backward(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10 [0%----------------------------------------------------]\n",
      "wires:\n",
      " [array([0.1, 0.3, 0.5, 0.2]), array([0.66752639, 0.46498727, 0.41519548]), array([0.17724469, 0.13084457])]\n",
      "gradientes:\n",
      " [array([0.22193491, 0.24877411, 0.24280819]), array([0.14582901, 0.11372427])]\n",
      "\n",
      "\n",
      ">camada:0\n",
      "input: [0.1 0.3 0.5 0.2]\n",
      "output: [0.66752639 0.46498727 0.41519548]\n",
      "gradiente: [0.22193491 0.24877411 0.24280819]\n",
      "=>camada:1\n",
      "input: [0.66752639 0.46498727 0.41519548]\n",
      "output: [0.16128023 0.09271827]\n",
      "gradiente: [0.13526892 0.08412159]\n",
      "\n",
      "Back Propagation:\n",
      "inputs outputs: [array([0.1, 0.3, 0.5, 0.2]), array([0.66752639, 0.46498727, 0.41519548]), array([0.16128023, 0.09271827])]\n",
      "\n",
      "grads [0.22193491 0.24877411 0.24280819]:\n",
      "weigths [[-1.01123836 -1.56697883]\n",
      " [-0.81028906 -1.55162622]\n",
      " [-1.43771031 -1.23652925]]:\n",
      "error_term [array([[-0.00067779, -0.00061664, -0.00111285],\n",
      "       [-0.0053666 , -0.00639224, -0.00487515]]), array([0.00331838, 0.01923708])]:\n",
      "grads * weights [[-0.00074474 -0.00066892 -0.00115841]\n",
      " [-0.00669003 -0.0074256  -0.00577573]]:\n",
      "=>camada 1\n",
      "input : [0.66752639 0.46498727 0.41519548]\n",
      "output: [0.16128023 0.09271827]\n",
      "erro: [0.03871977 0.20728173]\n",
      "error_term: [array([[-0.00117547, -0.00105579, -0.00182838],\n",
      "       [-0.00606397, -0.00673071, -0.00523524]]), array([0.00523758, 0.01743687])]\n",
      "pesos: [[-1.01123836 -1.56697883]\n",
      " [-0.81028906 -1.55162622]\n",
      " [-1.43771031 -1.23652925]]\n",
      "lole \n",
      "[array([0.00349622, 0.01163957]), array([0.00243541, 0.00810792]), array([0.00217462, 0.00723971])]\n",
      "dw shape:[[-0.06060534 -0.20665387]\n",
      " [-0.04221662 -0.14395149]\n",
      " [-0.03769598 -0.12853687]]\n",
      "pesos dw camada -1: \n",
      "[[-0.05710911 -0.1950143 ]\n",
      " [-0.03978121 -0.13584357]\n",
      " [-0.03552136 -0.12129716]]\n",
      "pesos camada -1: \n",
      "[[-1.09690203 -1.85950029]\n",
      " [-0.86996088 -1.75539157]\n",
      " [-1.49099235 -1.418475  ]]\n",
      "inputs camada -1: \n",
      "[0.66752639 0.46498727 0.41519548]\n",
      ">camada 0\n",
      "input : [0.1 0.3 0.5 0.2]\n",
      "output: [0.66752639 0.46498727 0.41519548]\n",
      "dwcamada:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "wires caralho:\n",
      "[0.1 0.3 0.5 0.2]\n",
      "error_term:\n",
      "[array([[-0.00117547, -0.00105579, -0.00182838],\n",
      "       [-0.00606397, -0.00673071, -0.00523524]]), array([0.00523758, 0.01743687])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (4,2,3) (4,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-42f3365b3f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-de58cab81f25>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wires caralho:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamada\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error_term:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamada\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0merror_term\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamada\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamada\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dwcamada:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamada\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m    \u001b[0;31m#     weights[camada] += np.dot (learnrate / epoch+1,dw[camada])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (4,2,3) (4,3) "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "b=barrinha(epochs)\n",
    "for epoch in range(epochs):\n",
    "    b.refresh(epoch)\n",
    "    print(\"epoch: {}/{} {}\".format(epoch + 1,epochs,b))\n",
    "    print(\"wires:\\n {}\".format(wires))\n",
    "    print(\"gradientes:\\n {}\".format(grads))\n",
    "    print('\\n')\n",
    "    next(foward())\n",
    "    next(backward(epoch + 1))\n",
    "    print('='*100+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
